{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Segmentation Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the `onem_segment` module for automatic Region of Interest (ROI) segmentation with intelligent 2D/3D model selection.\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Image Dimension Analysis](#analysis)\n",
    "3. [Single Image Segmentation](#single)\n",
    "4. [Batch Segmentation](#batch)\n",
    "5. [Model Comparison](#comparison)\n",
    "6. [Post-processing and Refinement](#postprocessing)\n",
    "7. [Results Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup and Imports {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Medical imaging imports\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import onem_segment modules\n",
    "from onem_segment import ROISegmenter\n",
    "from onem_segment.utils.image_analyzer import ImageDimensionAnalyzer\n",
    "from onem_segment.config.settings import get_preset_config\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Image Dimension Analysis {#analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image analyzer\n",
    "analyzer = ImageDimensionAnalyzer()\n",
    "print(\"üîç Image dimension analyzer initialized\")\n",
    "\n",
    "# Example image path (replace with your actual file path)\n",
    "image_path = \"sample_data/patient001_ct.nii.gz\"\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"üìÅ Analyzing image: {image_path}\")\n",
    "    \n",
    "    # Analyze image dimensions and characteristics\n",
    "    analysis = analyzer.analyze_image(image_path)\n",
    "    \n",
    "    print(\"\\nüìä Image Analysis Results:\")\n",
    "    print(f\"  Shape: {analysis['shape']}\")\n",
    "    print(f\"  Voxel spacing: {analysis['voxel_spacing']}\")\n",
    "    print(f\"  Data type: {analysis['data_type']}\")\n",
    "    print(f\"  Intensity range: [{analysis['min_intensity']:.2f}, {analysis['max_intensity']:.2f}]\")\n",
    "    \n",
    "    # 2D/3D recommendation\n",
    "    print(f\"\\nüéØ Model Recommendation:\")\n",
    "    print(f\"  Recommended mode: {analysis['recommended_mode']}\")\n",
    "    print(f\"  Confidence: {analysis['confidence']:.2f}\")\n",
    "    \n",
    "    # Analysis details\n",
    "    print(f\"\\nüî¨ Analysis Details:\")\n",
    "    print(f\"  Slice count: {analysis['slice_count']} (threshold: 30)\")\n",
    "    print(f\"  Slice thickness: {analysis['slice_thickness']:.2f}mm (threshold: 5mm)\")\n",
    "    print(f\"  Content variation: {analysis['content_variation']:.2f} (threshold: 0.10)\")\n",
    "    print(f\"  Criteria met: {analysis['criteria_met']}/3\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Sample image not found: {image_path}\")\n",
    "    print(\"Please replace with your actual NIfTI file path\")\n",
    "    \n",
    "# Create dummy analysis for demonstration\n",
    "analysis = {\n",
    "    'shape': (512, 512, 120),\n",
    "    'voxel_spacing': [0.7, 0.7, 3.0],\n",
    "    'slice_count': 120,\n",
    "    'slice_thickness': 3.0,\n",
    "    'content_variation': 0.15,\n",
    "    'recommended_mode': '3D',\n",
    "    'confidence': 0.85,\n",
    "    'criteria_met': 3\n",
    "}\n",
    "print(\"\\nüé≠ Using dummy analysis for demonstration:\")\n",
    "for key, value in analysis.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Single Image Segmentation {#single}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ROI segmenter\n",
    "segmenter = ROISegmenter()\n",
    "print(\"üéØ ROI segmenter initialized\")\n",
    "\n",
    "# Example image and output paths\n",
    "image_path = \"sample_data/patient001_ct.nii.gz\"\n",
    "output_path = \"output/segmentations/patient001_roi.nii.gz\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Check if image exists\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"üöÄ Starting segmentation...\")\n",
    "    \n",
    "    # Perform segmentation with automatic model selection\n",
    "    result = segmenter.segment_image(\n",
    "        image_path=image_path,\n",
    "        model_type='auto',  # '2d', '3d', or 'auto'\n",
    "        output_path=output_path,\n",
    "        config_name='ct_organ',  # Use CT organ segmentation preset\n",
    "        confidence_threshold=0.5\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Segmentation completed!\")\n",
    "    print(f\"üìä Model used: {result['model_used']}\")\n",
    "    print(f\"‚è±Ô∏è  Processing time: {result['processing_time']:.2f}s\")\n",
    "    print(f\"üìÅ Output saved to: {result['output_path']}\")\n",
    "    \n",
    "    # Display segmentation statistics\n",
    "    if 'statistics' in result:\n",
    "        stats = result['statistics']\n",
    "        print(f\"\\nüìà Segmentation Statistics:\")\n",
    "        print(f\"  ROI volume: {stats.get('roi_volume', 'N/A')} voxels\")\n",
    "        print(f\"  ROI percentage: {stats.get('roi_percentage', 'N/A')}%\")\n",
    "        print(f\"  Connected components: {stats.get('connected_components', 'N/A')}\")\n",
    "        print(f\"  Largest component: {stats.get('largest_component_size', 'N/A')} voxels\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Sample image not found: {image_path}\")\n",
    "    print(\"Please replace with your actual NIfTI file path\")\n",
    "    \n",
    "# Create dummy result for demonstration\n",
    "result = {\n",
    "    'model_used': '3D',\n",
    "    'processing_time': 45.6,\n",
    "    'output_path': 'output/segmentations/patient001_roi.nii.gz',\n",
    "    'statistics': {\n",
    "        'roi_volume': 15420,\n",
    "        'roi_percentage': 2.8,\n",
    "        'connected_components': 3,\n",
    "        'largest_component_size': 12350\n",
    "    }\n",
    "}\n",
    "print(\"\\nüé≠ Using dummy result for demonstration:\")\n",
    "for key, value in result.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  {key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Batch Segmentation {#batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing setup\n",
    "image_dir = \"sample_data/images/\"\n",
    "output_dir = \"output/batch_segmentations/\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Check if directory exists\n",
    "if os.path.exists(image_dir):\n",
    "    print(f\"üìÅ Processing images from: {image_dir}\")\n",
    "    print(f\"üìÅ Output directory: {output_dir}\")\n",
    "    \n",
    "    # Perform batch segmentation\n",
    "    print(\"üöÄ Starting batch segmentation...\")\n",
    "    results = segmenter.segment_batch(\n",
    "        image_dir=image_dir,\n",
    "        output_dir=output_dir,\n",
    "        model_type='auto',\n",
    "        config_name='ct_organ',\n",
    "        parallel=True,  # Enable parallel processing\n",
    "        n_workers=4\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Batch segmentation completed!\")\n",
    "    print(f\"üìä Processed {len(results)} images\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    processing_times = [r['processing_time'] for r in results if 'processing_time' in r]\n",
    "    models_used = [r['model_used'] for r in results if 'model_used' in r]\n",
    "    \n",
    "    print(f\"\\nüìà Batch Processing Summary:\")\n",
    "    print(f\"  Total processing time: {sum(processing_times):.2f}s\")\n",
    "    print(f\"  Average time per image: {np.mean(processing_times):.2f}s\")\n",
    "    print(f\"  2D models used: {models_used.count('2D')}\")\n",
    "    print(f\"  3D models used: {models_used.count('3D')}\")\n",
    "    \n",
    "    # Display individual results\n",
    "    print(f\"\\nüëÄ Individual Results:\")\n",
    "    for i, result in enumerate(results[:5]):  # Show first 5\n",
    "        print(f\"  {i+1}. {os.path.basename(result.get('image_path', 'unknown'))}: \")\n",
    "        print(f\"     Model: {result.get('model_used', 'unknown')}, \")\n",
    "        print(f\"     Time: {result.get('processing_time', 'unknown')}s\")\n",
    "    \n",
    "    if len(results) > 5:\n",
    "        print(f\"  ... and {len(results) - 5} more results\")\nelse:\n",
    "    print(f\"‚ö†Ô∏è  Sample directory not found: {image_dir}\")\n",
    "    print(\"Please replace with your actual image directory path\")\n",
    "    \n",
    "# Create dummy batch results for demonstration\n",
    "dummy_results = [\n",
    "    {'image_path': 'patient001.nii.gz', 'model_used': '3D', 'processing_time': 45.6},\n",
    "    {'image_path': 'patient002.nii.gz', 'model_used': '2D', 'processing_time': 23.4},\n",
    "    {'image_path': 'patient003.nii.gz', 'model_used': '3D', 'processing_time': 67.8},\n",
    "    {'image_path': 'patient004.nii.gz', 'model_used': '2D', 'processing_time': 18.9},\n",
    "    {'image_path': 'patient005.nii.gz', 'model_used': '3D', 'processing_time': 52.1}\n",
    "]\n",
    "\n",
    "print(\"\\nüé≠ Using dummy batch results for demonstration:\")\n",
    "processing_times = [r['processing_time'] for r in dummy_results]\n",
    "models_used = [r['model_used'] for r in dummy_results]\n",
    "\n",
    "print(f\"  Total processed: {len(dummy_results)} images\")\n",
    "print(f\"  Total time: {sum(processing_times):.2f}s\")\n",
    "print(f\"  Average time: {np.mean(processing_times):.2f}s\")\n",
    "print(f\"  2D models: {models_used.count('2D')}, 3D models: {models_used.count('3D')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Model Comparison {#comparison}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models on the same image\n",
    "image_path = \"sample_data/patient001_ct.nii.gz\"\n",
    "output_base = \"output/model_comparison/\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"üîç Comparing models on: {image_path}\")\n",
    "    \n",
    "    # Test different model types\n",
    "    model_types = ['2d', '3d', 'auto']\n",
    "    comparison_results = {}\n",
    "    \n",
    "    for model_type in model_types:\n",
    "        print(f\"\\nüöÄ Testing {model_type.upper()} model...\")\n",
    "        \n",
    "        output_path = os.path.join(output_base, f\"patient001_{model_type}_roi.nii.gz\")\n",
    "        \n",
    "        try:\n",
    "            result = segmenter.segment_image(\n",
    "                image_path=image_path,\n",
    "                model_type=model_type,\n",
    "                output_path=output_path,\n",
    "                config_name='ct_organ'\n",
    "            )\n",
    "            \n",
    "            comparison_results[model_type] = result\n",
    "            print(f\"  ‚úÖ Completed in {result['processing_time']:.2f}s\")\n",
    "            print(f\"  üìä Model used: {result['model_used']}\")\n",
    "            \n",
    "            if 'statistics' in result:\n",
    "                stats = result['statistics']\n",
    "                print(f\"  üìà ROI volume: {stats.get('roi_volume', 'N/A')} voxels\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error: {e}\")\n",
    "            comparison_results[model_type] = {'error': str(e)}\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(\"\\nüìä Model Comparison Summary:\")\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_type, result in comparison_results.items():\n",
    "        if 'error' not in result:\n",
    "            comparison_data.append({\n",
    "                'Model Type': model_type.upper(),\n",
    "                'Actual Model': result.get('model_used', 'N/A'),\n",
    "                'Processing Time (s)': result.get('processing_time', 0),\n",
    "                'ROI Volume': result.get('statistics', {}).get('roi_volume', 0)\n",
    "            })\n",
    "        else:\n",
    "            comparison_data.append({\n",
    "                'Model Type': model_type.upper(),\n",
    "                'Actual Model': 'Error',\n",
    "                'Processing Time (s)': 0,\n",
    "                'ROI Volume': 0\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    display(comparison_df)\nelse:\n",
    "    print(f\"‚ö†Ô∏è  Sample image not found: {image_path}\")\n",
    "    \n",
    "# Create dummy comparison for demonstration\n",
    "dummy_comparison = pd.DataFrame({\n",
    "    'Model Type': ['2D', '3D', 'AUTO'],\n",
    "    'Actual Model': ['2D', '3D', '3D'],\n",
    "    'Processing Time (s)': [23.4, 67.8, 45.6],\n",
    "    'ROI Volume': [15420, 16234, 15987]\n",
    "})\n",
    "\n",
    "print(\"\\nüé≠ Using dummy comparison for demonstration:\")\n",
    "display(dummy_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Post-processing and Refinement {#postprocessing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate post-processing options\n",
    "if os.path.exists(image_path) and 'result' in locals():\n",
    "    print(\"üîß Demonstrating post-processing options...\")\n",
    "    \n",
    "    # 1. Connected component analysis\n",
    "    print(\"\\nüîç Connected Component Analysis:\")\n",
    "    cca_result = segmenter.apply_connected_component_analysis(\n",
    "        result['output_path'],\n",
    "        min_size=100,  # Minimum component size\n",
    "        keep_largest=True\n",
    "    )\n",
    "    print(f\"  Original components: {cca_result['original_components']}\")\n",
    "    print(f\"  Filtered components: {cca_result['filtered_components']}\")\n",
    "    print(f\"  Largest component size: {cca_result['largest_component_size']}\")\n",
    "    \n",
    "    # 2. Morphological operations\n",
    "    print(\"\\nüî® Morphological Operations:\")\n",
    "    morph_result = segmenter.apply_morphological_operations(\n",
    "        result['output_path'],\n",
    "        operation='closing',  # 'opening', 'closing', 'erosion', 'dilation'\n",
    "        kernel_size=3,\n",
    "        iterations=2\n",
    "    )\n",
    "    print(f\"  Operation: {morph_result['operation']}\")\n",
    "    print(f\"  Kernel size: {morph_result['kernel_size']}\")\n",
    "    print(f\"  Volume change: {morph_result['volume_change']:.2f}%\")\n",
    "    \n",
    "    # 3. Boundary refinement\n",
    "    print(\"\\nüéØ Boundary Refinement:\")\n",
    "    boundary_result = segmenter.refine_boundaries(\n",
    "        result['output_path'],\n",
    "        image_path=image_path,\n",
    "        method='active_contour',  # 'active_contour', 'graph_cut'\n",
    "        iterations=50\n",
    "    )\n",
    "    print(f\"  Method: {boundary_result['method']}\")\n",
    "    print(f\"  Iterations: {boundary_result['iterations']}\")\n",
    "    print(f\"  Convergence: {boundary_result['convergence']:.4f}\")\n",
    "    print(f\"  Boundary change: {boundary_result['boundary_change']:.2f}%\")\nelse:\n",
    "    print(\"‚ö†Ô∏è  No segmentation result available for post-processing\")\n",
    "    \n",
    "# Create dummy post-processing results for demonstration\n",
    "dummy_cca = {\n",
    "    'original_components': 5,\n",
    "    'filtered_components': 2,\n",
    "    'largest_component_size': 12350\n",
    "}\n",
    "\n",
    "dummy_morph = {\n",
    "    'operation': 'closing',\n",
    "    'kernel_size': 3,\n",
    "    'volume_change': -2.3\n",
    "}\n",
    "\n",
    "dummy_boundary = {\n",
    "    'method': 'active_contour',\n",
    "    'iterations': 50,\n",
    "    'convergence': 0.0001,\n",
    "    'boundary_change': 5.7\n",
    "}\n",
    "\n",
    "print(\"\\nüé≠ Using dummy post-processing results for demonstration:\")\n",
    "print(\"\\nüîç Connected Component Analysis:\")\n",
    "for key, value in dummy_cca.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüî® Morphological Operations:\")\n",
    "for key, value in dummy_morph.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüéØ Boundary Refinement:\")\n",
    "for key, value in dummy_boundary.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Results Visualization {#visualization}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations of segmentation results\n",
    "if 'results' in locals() or 'dummy_results' in locals():\n",
    "    # Use actual or dummy results\n",
    "    batch_results = results if 'results' in locals() else dummy_results\n",
    "    \n",
    "    # 1. Processing time comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('ROI Segmentation Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Processing times\n",
    "    processing_times = [r.get('processing_time', 0) for r in batch_results]\n",
    "    image_names = [os.path.basename(r.get('image_path', f'Image {i+1}')) \n",
    "                   for i, r in enumerate(batch_results)]\n",
    "    \n",
    "    axes[0, 0].bar(range(len(image_names)), processing_times, color='skyblue', alpha=0.7)\n",
    "    axes[0, 0].set_title('Processing Time per Image')\n",
    "    axes[0, 0].set_xlabel('Image')\n",
    "    axes[0, 0].set_ylabel('Time (seconds)')\n",
    "    axes[0, 0].set_xticks(range(len(image_names)))\n",
    "    axes[0, 0].set_xticklabels(image_names, rotation=45, ha='right')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Model type distribution\n",
    "    models_used = [r.get('model_used', 'Unknown') for r in batch_results]\n",
    "    model_counts = pd.Series(models_used).value_counts()\n",
    "    \n",
    "    axes[0, 1].pie(model_counts.values, labels=model_counts.index, autopct='%1.1f%%', \n",
    "                   colors=['lightcoral', 'lightblue'])\n",
    "    axes[0, 1].set_title('Model Type Distribution')\n",
    "    \n",
    "    # Processing time statistics\n",
    "    if processing_times:\n",
    "        time_stats = {\n",
    "            'Min': min(processing_times),\n",
    "            'Max': max(processing_times),\n",
    "            'Mean': np.mean(processing_times),\n",
    "            'Median': np.median(processing_times)\n",
    "        }\n",
    "        \n",
    "        axes[1, 0].bar(time_stats.keys(), time_stats.values(), \n",
    "                       color=['green', 'red', 'blue', 'orange'], alpha=0.7)\n",
    "        axes[1, 0].set_title('Processing Time Statistics')\n",
    "        axes[1, 0].set_ylabel('Time (seconds)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROI volumes (if available)\n",
    "    roi_volumes = []\n",
    "    for r in batch_results:\n",
    "        if 'statistics' in r and 'roi_volume' in r['statistics']:\n",
    "            roi_volumes.append(r['statistics']['roi_volume'])\n",
    "    \n",
    "    if roi_volumes:\n",
    "        axes[1, 1].hist(roi_volumes, bins=10, alpha=0.7, color='gold', edgecolor='black')\n",
    "        axes[1, 1].set_title('ROI Volume Distribution')\n",
    "        axes[1, 1].set_xlabel('ROI Volume (voxels)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'ROI Volume Data\\nNot Available', \n",
    "                       ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('ROI Volume Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Model comparison heatmap\n",
    "    if 'comparison_df' in locals() or 'dummy_comparison' in locals():\n",
    "        comp_data = comparison_df if 'comparison_df' in locals() else dummy_comparison\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create comparison metrics\n",
    "        metrics = ['Processing Time (s)', 'ROI Volume']\n",
    "        comparison_matrix = comp_data[metrics].values\n",
    "        \n",
    "        # Normalize for better visualization\n",
    "        normalized_matrix = comparison_matrix / comparison_matrix.max(axis=0)\n",
    "        \n",
    "        sns.heatmap(normalized_matrix.T, \n",
    "                   annot=comp_data[metrics].T, \n",
    "                   xticklabels=comp_data['Model Type'],\n",
    "                   yticklabels=metrics,\n",
    "                   cmap='YlOrRd', \n",
    "                   fmt='.1f',\n",
    "                   cbar_kws={'label': 'Normalized Value'})\n",
    "        \n",
    "        plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\nelse:\n",
    "    print(\"‚ö†Ô∏è  No results available for visualization\")\n",
    "    \n",
    "# Create sample visualizations with dummy data\n",
    "print(\"üìä Creating sample visualizations...\")\n",
    "\n",
    "# Sample data\n",
    "sample_times = [23.4, 67.8, 45.6, 18.9, 52.1]\n",
    "sample_images = ['Patient 001', 'Patient 002', 'Patient 003', 'Patient 004', 'Patient 005']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('ROI Segmentation Sample Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Processing time bar chart\n",
    "axes[0, 0].bar(sample_images, sample_times, color='skyblue', alpha=0.7)\n",
    "axes[0, 0].set_title('Processing Time per Patient')\n",
    "axes[0, 0].set_ylabel('Time (seconds)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Time distribution histogram\n",
    "axes[0, 1].hist(sample_times, bins=5, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_title('Processing Time Distribution')\n",
    "axes[0, 1].set_xlabel('Time (seconds)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Time statistics\n",
    "time_stats = [min(sample_times), max(sample_times), np.mean(sample_times), np.median(sample_times)]\n",
    "stat_labels = ['Min', 'Max', 'Mean', 'Median']\n",
    "stat_colors = ['green', 'red', 'blue', 'orange']\n",
    "\n",
    "axes[1, 0].bar(stat_labels, time_stats, color=stat_colors, alpha=0.7)\n",
    "axes[1, 0].set_title('Processing Time Statistics')\n",
    "axes[1, 0].set_ylabel('Time (seconds)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Model performance comparison\n",
    "models = ['2D', '3D', 'Auto']\n",
    "avg_times = [21.15, 59.8, 40.35]  # Average times\n",
    "\n",
    "axes[1, 1].bar(models, avg_times, color=['lightcoral', 'lightblue', 'gold'], alpha=0.7)\n",
    "axes[1, 1].set_title('Average Time by Model Type')\n",
    "axes[1, 1].set_ylabel('Average Time (seconds)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary and Best Practices\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Auto Model Selection**: The 'auto' mode intelligently chooses between 2D and 3D models\n",
    "2. **Processing Time**: 2D models are faster (~3x) but 3D models may be more accurate for thick volumes\n",
    "3. **Post-processing**: Essential for cleaning up segmentation results\n",
    "4. **Batch Processing**: Use parallel processing for multiple images\n",
    "5. **Quality Control**: Always visualize and validate segmentation results\n",
    "\n",
    "### Decision Criteria for Model Selection:\n",
    "- **Slice Count**: ‚â•30 slices favors 3D\n",
    "- **Slice Thickness**: ‚â§5mm favors 3D  \n",
    "- **Content Variation**: ‚â•10% variation favors 3D\n",
    "- **Confidence**: Higher confidence means more reliable auto-selection\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "- ‚ö†Ô∏è **Memory errors** with large 3D images ‚Üí Use 2D mode or increase memory\n",
    "- ‚ö†Ô∏è **Over-segmentation** ‚Üí Apply connected component analysis\n",
    "- ‚ö†Ô∏è **Under-segmentation** ‚Üí Try different confidence thresholds\n",
    "- ‚ö†Ô∏è **Noisy boundaries** ‚Üí Apply morphological operations\n",
    "\n",
    "### Next Steps:\n",
    "- üîó Combine segmentation with radiomics extraction\n",
    "- üìä Use segmentation masks for feature extraction\n",
    "- üß™ Validate segmentation with expert annotations\n",
    "- üéØ Fine-tune models for specific anatomical structures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}