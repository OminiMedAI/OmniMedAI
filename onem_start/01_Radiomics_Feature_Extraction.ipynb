{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radiomics Feature Extraction Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the `onem_radiomics` module to extract comprehensive radiomics features from medical images and masks.\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Single Image Feature Extraction](#single)\n",
    "3. [Batch Processing](#batch)\n",
    "4. [Feature Analysis](#analysis)\n",
    "5. [Configuration Management](#config)\n",
    "6. [Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup and Imports {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import onem_radiomics modules\n",
    "from onem_radiomics import RadiomicsExtractor\n",
    "from onem_radiomics.config.settings import get_preset_config\n",
    "from onem_radiomics.utils.radiomics_utils import analyze_features\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Single Image Feature Extraction {#single}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the radiomics extractor\n",
    "extractor = RadiomicsExtractor()\n",
    "print(\"üî¨ Radiomics extractor initialized\")\n",
    "\n",
    "# Example paths (replace with your actual file paths)\n",
    "image_path = \"sample_data/patient001_ct.nii.gz\"\n",
    "mask_path = \"sample_data/patient001_mask.nii.gz\"\n",
    "\n",
    "# Check if sample data exists\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"‚ö†Ô∏è  Sample image not found: {image_path}\")\n",
    "    print(\"Please replace with your actual NIfTI file paths\")\n",
    "else:\n",
    "    # Extract features with default CT configuration\n",
    "    print(\"üöÄ Extracting features...\")\n",
    "    features = extractor.extract_features(\n",
    "        image_path=image_path,\n",
    "        mask_path=mask_path,\n",
    "        config_name='ct_lung'  # Use CT lung cancer preset\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Extracted {len(features)} features\")\n",
    "    print(\"\\nüìã Sample features:\")\n",
    "    for i, (key, value) in enumerate(list(features.items())[:10]):\n",
    "        print(f\"  {i+1:2d}. {key}: {value:.4f}\")\n",
    "    \n",
    "    if len(features) > 10:\n",
    "        print(f\"  ... and {len(features) - 10} more features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Batch Processing {#batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing setup\n",
    "image_dir = \"sample_data/images/\"\n",
    "mask_dir = \"sample_data/masks/\"\n",
    "output_csv = \"output/radiomics_features.csv\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "\n",
    "# Check if directories exist\n",
    "if os.path.exists(image_dir) and os.path.exists(mask_dir):\n",
    "    print(f\"üìÅ Processing images from: {image_dir}\")\n",
    "    print(f\"üìÅ Processing masks from: {mask_dir}\")\n",
    "    \n",
    "    # Extract features for all images in the directories\n",
    "    results = extractor.extract_batch(\n",
    "        image_dir=image_dir,\n",
    "        mask_dir=mask_dir,\n",
    "        output_csv=output_csv,\n",
    "        config_name='ct_lung',\n",
    "        parallel=True,  # Enable parallel processing\n",
    "        n_workers=4     # Number of parallel workers\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Batch processing completed!\")\n",
    "    print(f\"üìä Results saved to: {output_csv}\")\n",
    "    \n",
    "    # Load and display results\n",
    "    df = pd.read_csv(output_csv)\n",
    "    print(f\"\\nüìà Processed {len(df)} cases\")\n",
    "    print(f\"üìã Feature columns: {len(df.columns) - 1}\")  # -1 for ID column\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nüëÄ Sample results:\")\n",
    "    display(df.head())\nelse:\n",
    "    print(f\"‚ö†Ô∏è  Sample directories not found:\")\n",
    "    print(f\"   Images: {image_dir}\")\n",
    "    print(f\"   Masks: {mask_dir}\")\n",
    "    print(\"Please replace with your actual directory paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Feature Analysis {#analysis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have results from batch processing, analyze them\n",
    "if 'df' in locals():\n",
    "    print(\"üîç Performing feature analysis...\")\n",
    "    \n",
    "    # Get feature columns (excluding ID column)\n",
    "    feature_cols = [col for col in df.columns if col != 'PatientID']\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nüìä Feature Statistics:\")\n",
    "    stats_df = df[feature_cols].describe().T\n",
    "    display(stats_df[['mean', 'std', 'min', 'max']].head(10))\n",
    "    \n",
    "    # Feature correlation analysis\n",
    "    print(\"\\nüîó Computing feature correlations...\")\n",
    "    correlation_matrix = df[feature_cols].corr()\n",
    "    \n",
    "    # Find highly correlated features\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.9:  # High correlation threshold\n",
    "                high_corr_pairs.append((\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    corr_val\n",
    "                ))\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Found {len(high_corr_pairs)} highly correlated feature pairs (|r| > 0.9):\")\n",
    "    for i, (feat1, feat2, corr) in enumerate(high_corr_pairs[:10]):\n",
    "        print(f\"  {i+1:2d}. {feat1} ‚Üî {feat2}: r = {corr:.3f}\")\n",
    "    \n",
    "    if len(high_corr_pairs) > 10:\n",
    "        print(f\"  ... and {len(high_corr_pairs) - 10} more pairs\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No batch processing results available for analysis\")\n",
    "    print(\"Run the batch processing cell first to generate data for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration Management {#config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore available preset configurations\n",
    "print(\"üìã Available preset configurations:\")\n",
    "preset_configs = [\n",
    "    'default', 'ct_lung', 'ct_brain', 'mri_brain', \n",
    "    'pet_tumor', 'research', 'production'\n",
    "]\n",
    "\n",
    "for config_name in preset_configs:\n",
    "    try:\n",
    "        config = get_preset_config(config_name)\n",
    "        print(f\"\\nüîß {config_name}:\")\n",
    "        print(f\"  - Image type: {config.get('image_type', 'unknown')}\")\n",
    "        print(f\"  - Feature types: {', '.join(config.get('feature_types', []))}\")\n",
    "        print(f\"  - Bin width: {config.get('bin_width', 'N/A')}\")\n",
    "        print(f\"  - Resampling: {config.get('resampling', 'disabled')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Error loading {config_name}: {e}\")\n",
    "\n",
    "# Create custom configuration\n",
    "print(\"\\nüé® Creating custom configuration...\")\n",
    "custom_config = {\n",
    "    'image_type': 'CT',\n",
    "    'feature_types': ['firstorder', 'texture'],\n",
    "    'bin_width': 20,\n",
    "    'resampling': {\n",
    "        'voxel_size': [1.0, 1.0, 3.0],  # Isotropic voxels\n",
    "        'interpolator': 'sitkBSpline'\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'normalize': True,\n",
    "        'remove_outliers': True\n",
    "    },\n",
    "    'texture_settings': {\n",
    "        'glcm_distances': [1, 2, 3],\n",
    "        'glrlm_distances': [1, 2, 3]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Custom configuration created\")\n",
    "print(f\"üìã Custom config: {custom_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualization {#visualization}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have results, create visualizations\n",
    "if 'df' in locals() and len(df) > 1:\n",
    "    feature_cols = [col for col in df.columns if col != 'PatientID']\n",
    "    \n",
    "    # 1. Feature distribution plot\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Feature Distributions', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot first 6 features\n",
    "    for i, feature in enumerate(feature_cols[:6]):\n",
    "        row, col = i // 3, i % 3\n",
    "        axes[row, col].hist(df[feature].dropna(), bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[row, col].set_title(feature)\n",
    "        axes[row, col].set_xlabel('Value')\n",
    "        axes[row, col].set_ylabel('Frequency')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Correlation heatmap (subset)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    correlation_subset = df[feature_cols[:15]].corr()  # First 15 features\n",
    "    \n",
    "    mask = np.triu(np.ones_like(correlation_subset, dtype=bool))\n",
    "    sns.heatmap(correlation_subset, mask=mask, annot=True, cmap='coolwarm', \n",
    "                center=0, square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Feature Correlation Heatmap (First 15 Features)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Box plot for selected features\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle('Feature Box Plots', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # First-order features\n",
    "    first_order_features = [col for col in feature_cols \n",
    "                           if any(keyword in col.lower() \n",
    "                                 for keyword in ['mean', 'median', 'std', 'skewness', 'kurtosis'])][:4]\n",
    "    \n",
    "    if first_order_features:\n",
    "        df[first_order_features].boxplot(ax=axes[0])\n",
    "        axes[0].set_title('First-Order Features')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Texture features\n",
    "    texture_features = [col for col in feature_cols \n",
    "                        if any(keyword in col.lower() \n",
    "                              for keyword in ['glcm', 'glrlm', 'glszm'])][:4]\n",
    "    \n",
    "    if texture_features:\n",
    "        df[texture_features].boxplot(ax=axes[1])\n",
    "        axes[1].set_title('Texture Features')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Feature importance (variance-based)\n",
    "    feature_variance = df[feature_cols].var().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_features = feature_variance.head(15)\n",
    "    top_features.plot(kind='bar')\n",
    "    plt.title('Top 15 Features by Variance', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Variance')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No data available for visualization\")\n",
    "    print(\"Run the batch processing cell first to generate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary and Best Practices\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Single vs Batch**: Use `extract_features()` for individual cases, `extract_batch()` for multiple cases\n",
    "2. **Configuration**: Choose appropriate preset configs or create custom ones\n",
    "3. **Parallel Processing**: Enable parallel processing for large datasets\n",
    "4. **Feature Analysis**: Always analyze feature correlations and distributions\n",
    "5. **Quality Control**: Check for missing values and outliers\n",
    "\n",
    "### Common Pitfalls:\n",
    "- ‚ö†Ô∏è Mismatched image and mask dimensions\n",
    "- ‚ö†Ô∏è Incorrect file paths or permissions\n",
    "- ‚ö†Ô∏è Memory issues with large 3D images\n",
    "- ‚ö†Ô∏è Inconsistent preprocessing across batches\n",
    "\n",
    "### Next Steps:\n",
    "- üîÑ Combine with segmentation results from `onem_segment`\n",
    "- üîó Use features for machine learning models\n",
    "- üìä Perform feature selection and dimensionality reduction\n",
    "- üß™ Validate features on independent test sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}